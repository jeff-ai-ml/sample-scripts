{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeff-ai-ml/sample-scripts/blob/main/multi_layer_perceptron_pima_indians_additions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7Mszl2EYHgRA"
      },
      "outputs": [],
      "source": [
        "# Create your first MLP in Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"https://raw.githubusercontent.com/jeff-ai-ml/neural-network-datasets/refs/heads/main/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]"
      ],
      "metadata": {
        "id": "pK35jltuHi-5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "hECj6ciEHm44",
        "outputId": "d87b1d07-9c34-49f2-865e-42bc6011810c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m108\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m221\u001b[0m (884.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221</span> (884.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m221\u001b[0m (884.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221</span> (884.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "    if hasattr(layer, 'kernel_initializer'):\n",
        "        print(f\"Layer {i} - {layer.name}:\")\n",
        "        print(\"  Kernel Initializer:\", layer.kernel_initializer)\n",
        "        print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UulnFmuL42h0",
        "outputId": "2a1582cf-dfba-4ab2-9685-b44fdd8c65b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0 - dense_3:\n",
            "  Kernel Initializer: <keras.src.initializers.random_initializers.GlorotUniform object at 0x7cb48966bf10>\n",
            "\n",
            "Layer 1 - dense_4:\n",
            "  Kernel Initializer: <keras.src.initializers.random_initializers.GlorotUniform object at 0x7cb48967c850>\n",
            "\n",
            "Layer 2 - dense_5:\n",
            "  Kernel Initializer: <keras.src.initializers.random_initializers.GlorotUniform object at 0x7cb489684150>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#model.compile(optimizer='adam', loss='mse')\n",
        "print(\"\\n📌 Initial Weights:\")\n",
        "for layer in model.layers:\n",
        "    weights = layer.get_weights()\n",
        "    if weights:\n",
        "        print(f\"Layer {layer.name} weights:\\n\", weights[0])\n",
        "        print(f\"Layer {layer.name} biases:\\n\", weights[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEh4McsuHpgR",
        "outputId": "8f377b03-8c09-40bc-969e-1b5958435d8c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📌 Initial Weights:\n",
            "Layer dense_3 weights:\n",
            " [[ 0.23799068  0.21545744 -0.3631596   0.38109285 -0.02507877  0.0167895\n",
            "  -0.23424256  0.1414944   0.51146424 -0.08935067 -0.45122984  0.08219093]\n",
            " [-0.17493597 -0.41245276 -0.0116024   0.01438367  0.21299237  0.27041692\n",
            "  -0.31199655  0.3292107   0.22632086  0.31853777  0.49588454  0.5438826 ]\n",
            " [ 0.01847029 -0.23905417  0.24197006  0.4571724   0.10710818 -0.21451604\n",
            "  -0.44439098  0.5215298  -0.39689326  0.3238442   0.4808545   0.31063336]\n",
            " [ 0.03475642 -0.07469225 -0.26144755  0.22476012  0.20903218 -0.22718275\n",
            "   0.27099818 -0.07362822 -0.33379966 -0.3881997   0.0334993  -0.36413324]\n",
            " [ 0.28491783 -0.37188035  0.29269052 -0.51365614  0.3034026   0.06959021\n",
            "   0.23730743  0.33996493 -0.14873913 -0.07853633 -0.48750618  0.4950906 ]\n",
            " [-0.17275047  0.08808017 -0.29471162  0.28348333  0.28217524 -0.23118472\n",
            "   0.45508075 -0.32279652 -0.2449865   0.14221394  0.53772664  0.1225487 ]\n",
            " [ 0.01056021 -0.20375997  0.28267217  0.19636953 -0.54142725  0.05423301\n",
            "   0.3007244  -0.26023385 -0.22637859 -0.00941563 -0.23067307 -0.3737172 ]\n",
            " [ 0.36430836 -0.18541297 -0.43722188 -0.37602544  0.4665264  -0.40121767\n",
            "   0.31135237 -0.2914565   0.13810003  0.42840737 -0.13513482 -0.12500906]]\n",
            "Layer dense_3 biases:\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Layer dense_4 weights:\n",
            " [[ 0.08135426 -0.36239383  0.18879545 -0.5473086   0.36327136  0.24550688\n",
            "  -0.29762086  0.13206095]\n",
            " [ 0.44109577 -0.4631872  -0.38398668 -0.51395404  0.5238137   0.33407766\n",
            "  -0.40788507 -0.49592605]\n",
            " [ 0.4812534   0.04333091  0.47856092 -0.1023441   0.0397796   0.19867963\n",
            "  -0.06774214  0.3645143 ]\n",
            " [ 0.45043105 -0.0231688   0.4547801  -0.18187237 -0.3336829  -0.44984823\n",
            "  -0.27740085  0.10848951]\n",
            " [ 0.21973431 -0.30049756  0.13021988 -0.50939536  0.41853756  0.51433873\n",
            "  -0.5077403   0.2107395 ]\n",
            " [ 0.29312813  0.47203648  0.52774775 -0.20871824 -0.29182264 -0.31142914\n",
            "   0.54250133  0.03690773]\n",
            " [-0.42719865  0.40461957 -0.43538517 -0.13688365  0.20708865 -0.4104844\n",
            "  -0.09860107 -0.24267262]\n",
            " [ 0.11450762  0.00856495 -0.34934515 -0.27221328 -0.27713707 -0.5375297\n",
            "  -0.03396261 -0.19783705]\n",
            " [ 0.13996053  0.4419204   0.5043601  -0.35662788 -0.47062948 -0.11508471\n",
            "   0.44531238  0.38094962]\n",
            " [ 0.17864388  0.38417906  0.41300815 -0.53375876  0.11940742  0.52319205\n",
            "   0.07965457 -0.3473546 ]\n",
            " [ 0.10245651  0.09196931  0.48637605 -0.3236341  -0.3208753  -0.09730995\n",
            "  -0.16262278  0.09716266]\n",
            " [-0.41093165 -0.12482429 -0.3949406   0.2229563   0.3045302   0.3222341\n",
            "   0.03149879 -0.3690283 ]]\n",
            "Layer dense_4 biases:\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Layer dense_5 weights:\n",
            " [[-0.4823035 ]\n",
            " [ 0.79495585]\n",
            " [-0.62882304]\n",
            " [-0.37197077]\n",
            " [ 0.30381012]\n",
            " [-0.2890352 ]\n",
            " [ 0.70005715]\n",
            " [ 0.18182302]]\n",
            "Layer dense_5 biases:\n",
            " [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10)\n",
        "#evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB1KY9cz21N6",
        "outputId": "5c185fdd-c06f-4693-b0d3-da28fff27e0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6259 - loss: 5.4932\n",
            "Epoch 2/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5950 - loss: 1.3848\n",
            "Epoch 3/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6162 - loss: 1.1208\n",
            "Epoch 4/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6500 - loss: 0.8894\n",
            "Epoch 5/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6286 - loss: 0.8744\n",
            "Epoch 6/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6306 - loss: 0.7989\n",
            "Epoch 7/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6362 - loss: 0.7639\n",
            "Epoch 8/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6289 - loss: 0.7173\n",
            "Epoch 9/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6437 - loss: 0.6678\n",
            "Epoch 10/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6677 - loss: 0.6664\n",
            "Epoch 11/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6822 - loss: 0.6483\n",
            "Epoch 12/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6502 - loss: 0.6624\n",
            "Epoch 13/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6903 - loss: 0.6256\n",
            "Epoch 14/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7249 - loss: 0.5809\n",
            "Epoch 15/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6814 - loss: 0.6231\n",
            "Epoch 16/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6834 - loss: 0.6263\n",
            "Epoch 17/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7202 - loss: 0.5790\n",
            "Epoch 18/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 0.5892\n",
            "Epoch 19/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7053 - loss: 0.5659\n",
            "Epoch 20/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6711 - loss: 0.6134\n",
            "Epoch 21/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7407 - loss: 0.5656\n",
            "Epoch 22/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.5674\n",
            "Epoch 23/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7146 - loss: 0.6038\n",
            "Epoch 24/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7385 - loss: 0.5902\n",
            "Epoch 25/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7202 - loss: 0.5550\n",
            "Epoch 26/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.5786\n",
            "Epoch 27/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7208 - loss: 0.5846\n",
            "Epoch 28/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6965 - loss: 0.6483\n",
            "Epoch 29/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7146 - loss: 0.5759\n",
            "Epoch 30/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7218 - loss: 0.5736\n",
            "Epoch 31/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7112 - loss: 0.5560\n",
            "Epoch 32/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7239 - loss: 0.5823\n",
            "Epoch 33/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7320 - loss: 0.5665\n",
            "Epoch 34/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7406 - loss: 0.5365\n",
            "Epoch 35/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7676 - loss: 0.5201\n",
            "Epoch 36/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.5741\n",
            "Epoch 37/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7303 - loss: 0.5676\n",
            "Epoch 38/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.5383\n",
            "Epoch 39/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7346 - loss: 0.5494\n",
            "Epoch 40/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.5448\n",
            "Epoch 41/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6937 - loss: 0.5891\n",
            "Epoch 42/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7649 - loss: 0.5182\n",
            "Epoch 43/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7540 - loss: 0.5320\n",
            "Epoch 44/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.5808\n",
            "Epoch 45/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7481 - loss: 0.5116\n",
            "Epoch 46/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7748 - loss: 0.5153\n",
            "Epoch 47/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.5614\n",
            "Epoch 48/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7475 - loss: 0.5293\n",
            "Epoch 49/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7159 - loss: 0.5525\n",
            "Epoch 50/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7457 - loss: 0.5363\n",
            "Epoch 51/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7432 - loss: 0.5459\n",
            "Epoch 52/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7465 - loss: 0.5342\n",
            "Epoch 53/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7443 - loss: 0.5403\n",
            "Epoch 54/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7360 - loss: 0.5472\n",
            "Epoch 55/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7612 - loss: 0.5183\n",
            "Epoch 56/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7377 - loss: 0.5533\n",
            "Epoch 57/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7065 - loss: 0.5756\n",
            "Epoch 58/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7613 - loss: 0.4980\n",
            "Epoch 59/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7351 - loss: 0.5439\n",
            "Epoch 60/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5568\n",
            "Epoch 61/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7426 - loss: 0.5333\n",
            "Epoch 62/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7029 - loss: 0.5944\n",
            "Epoch 63/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7768 - loss: 0.5127\n",
            "Epoch 64/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7692 - loss: 0.5254\n",
            "Epoch 65/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7291 - loss: 0.5461\n",
            "Epoch 66/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7509 - loss: 0.5229\n",
            "Epoch 67/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7789 - loss: 0.4796\n",
            "Epoch 68/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7504 - loss: 0.5198\n",
            "Epoch 69/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7704 - loss: 0.5172\n",
            "Epoch 70/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.5174\n",
            "Epoch 71/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7498 - loss: 0.5218\n",
            "Epoch 72/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7793 - loss: 0.4932\n",
            "Epoch 73/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7158 - loss: 0.5444\n",
            "Epoch 74/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7082 - loss: 0.5473\n",
            "Epoch 75/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7584 - loss: 0.5335\n",
            "Epoch 76/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7215 - loss: 0.5317\n",
            "Epoch 77/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7378 - loss: 0.5573\n",
            "Epoch 78/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.5648\n",
            "Epoch 79/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7538 - loss: 0.5256\n",
            "Epoch 80/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.5216\n",
            "Epoch 81/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7558 - loss: 0.5291\n",
            "Epoch 82/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7576 - loss: 0.5090\n",
            "Epoch 83/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7437 - loss: 0.5333\n",
            "Epoch 84/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.5189\n",
            "Epoch 85/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7195 - loss: 0.5617\n",
            "Epoch 86/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7335 - loss: 0.5245\n",
            "Epoch 87/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7785 - loss: 0.4906\n",
            "Epoch 88/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7737 - loss: 0.4801\n",
            "Epoch 89/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7786 - loss: 0.4812\n",
            "Epoch 90/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7746 - loss: 0.4923\n",
            "Epoch 91/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7619 - loss: 0.5117\n",
            "Epoch 92/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7529 - loss: 0.5277\n",
            "Epoch 93/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7137 - loss: 0.5411\n",
            "Epoch 94/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7447 - loss: 0.5144\n",
            "Epoch 95/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7458 - loss: 0.5036\n",
            "Epoch 96/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7618 - loss: 0.5239\n",
            "Epoch 97/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7685 - loss: 0.4997\n",
            "Epoch 98/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7409 - loss: 0.5382\n",
            "Epoch 99/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7587 - loss: 0.5114\n",
            "Epoch 100/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7732 - loss: 0.4712\n",
            "Epoch 101/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7750 - loss: 0.5014\n",
            "Epoch 102/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7639 - loss: 0.5069\n",
            "Epoch 103/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7496 - loss: 0.5235\n",
            "Epoch 104/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7624 - loss: 0.5044\n",
            "Epoch 105/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7586 - loss: 0.4956\n",
            "Epoch 106/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7351 - loss: 0.5533\n",
            "Epoch 107/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7702 - loss: 0.4976\n",
            "Epoch 108/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7380 - loss: 0.5292\n",
            "Epoch 109/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7353 - loss: 0.5364\n",
            "Epoch 110/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7565 - loss: 0.5100\n",
            "Epoch 111/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7845 - loss: 0.4727\n",
            "Epoch 112/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7535 - loss: 0.5289\n",
            "Epoch 113/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7770 - loss: 0.4939\n",
            "Epoch 114/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7673 - loss: 0.4953\n",
            "Epoch 115/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7816 - loss: 0.4857\n",
            "Epoch 116/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7700 - loss: 0.5064\n",
            "Epoch 117/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7702 - loss: 0.4957\n",
            "Epoch 118/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7803 - loss: 0.4733\n",
            "Epoch 119/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7756 - loss: 0.5239\n",
            "Epoch 120/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7479 - loss: 0.5317\n",
            "Epoch 121/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7556 - loss: 0.5128\n",
            "Epoch 122/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7511 - loss: 0.4839\n",
            "Epoch 123/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.4930\n",
            "Epoch 124/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7655 - loss: 0.4851\n",
            "Epoch 125/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7964 - loss: 0.4948\n",
            "Epoch 126/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7740 - loss: 0.4952\n",
            "Epoch 127/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7886 - loss: 0.4725\n",
            "Epoch 128/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8064 - loss: 0.4671\n",
            "Epoch 129/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7727 - loss: 0.4757\n",
            "Epoch 130/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7492 - loss: 0.5388\n",
            "Epoch 131/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7730 - loss: 0.5036\n",
            "Epoch 132/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.5855\n",
            "Epoch 133/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7577 - loss: 0.5057\n",
            "Epoch 134/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7610 - loss: 0.5154\n",
            "Epoch 135/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7631 - loss: 0.4901\n",
            "Epoch 136/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.4780\n",
            "Epoch 137/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.5040\n",
            "Epoch 138/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7463 - loss: 0.5225\n",
            "Epoch 139/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7474 - loss: 0.5195\n",
            "Epoch 140/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7515 - loss: 0.5213\n",
            "Epoch 141/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7872 - loss: 0.4538\n",
            "Epoch 142/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7729 - loss: 0.5024\n",
            "Epoch 143/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7510 - loss: 0.5127\n",
            "Epoch 144/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7891 - loss: 0.4737\n",
            "Epoch 145/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7613 - loss: 0.4977\n",
            "Epoch 146/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7831 - loss: 0.4697\n",
            "Epoch 147/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7939 - loss: 0.4812\n",
            "Epoch 148/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7761 - loss: 0.4998\n",
            "Epoch 149/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7530 - loss: 0.5016\n",
            "Epoch 150/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7770 - loss: 0.4859\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7467 - loss: 0.5088  \n",
            "\n",
            "compile_metrics: 77.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    print(f\"Layer: {layer.name}\")\n",
        "    weights = layer.get_weights()\n",
        "    if weights:\n",
        "        print(f\"  Weights shape: {weights[0].shape}\")\n",
        "        print(f\"  Weights: \\n{weights[0]}\")\n",
        "        print(f\"  Biases shape: {weights[1].shape}\")\n",
        "        print(f\"  Biases: \\n{weights[1]}\")\n",
        "    else:\n",
        "        print(\"  No weights (e.g., Dropout or Flatten layer)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q08wMAhU3aMe",
        "outputId": "2ff0dde5-23ba-4528-dc85-fa94074bc985"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: dense_3\n",
            "  Weights shape: (8, 12)\n",
            "  Weights: \n",
            "[[ 0.8498324   0.21545744 -0.33652428  0.20295735 -0.03541667  0.24006018\n",
            "   0.3135134   0.24748485  0.18799654 -0.6018367  -0.4972695   0.3225189 ]\n",
            " [-0.11944436 -0.41245276  0.03898498  0.02013337  0.15093817  0.23962247\n",
            "  -0.40880162  0.35415632  0.11143947  0.09002046  0.35852882  0.53698605]\n",
            " [ 0.02552887 -0.23905417  0.34439996  0.36710986  0.06954916 -0.29904783\n",
            "  -0.4717286   0.45152634 -0.46716028  0.22340804  0.41423374  0.3138487 ]\n",
            " [-0.14595951 -0.07469225 -0.01121213  0.03224242 -0.05086758  0.20920625\n",
            "   0.2138151   0.04382552 -0.39622688 -0.3006366  -0.03306048 -0.22746612]\n",
            " [ 0.10700907 -0.37188035  0.31023392 -0.43448615 -0.05638752  0.04078705\n",
            "   0.09040141  0.26195753 -0.14873913 -0.07560864 -0.5981307   0.2791953 ]\n",
            " [-0.25962704  0.08808017 -0.24339545  0.05877262 -0.04299081 -0.06058691\n",
            "   0.5129875  -0.17184612 -0.46844253  0.28884843  0.35076797  0.25309575]\n",
            " [-0.2102152  -0.20375997 -0.39352113  0.01424075 -1.2200372   0.78074396\n",
            "   0.12302073  0.53705597 -0.5732979  -0.31021303 -1.0559897   0.33733156]\n",
            " [ 0.3752883  -0.18541297 -0.4136707  -0.42403415  0.3914155  -0.31846246\n",
            "   0.47788453 -0.28249902  0.17774698  0.23031443 -0.17035532 -0.08985741]]\n",
            "  Biases shape: (12,)\n",
            "  Biases: \n",
            "[ 0.07505354  0.          1.249865    0.2867777   0.7731648  -1.0536906\n",
            " -0.25280234 -1.1519884   0.46033248  0.20106636  0.87969685 -0.91006374]\n",
            "Layer: dense_4\n",
            "  Weights shape: (12, 8)\n",
            "  Weights: \n",
            "[[-0.0385626  -0.46050417 -0.24844995 -0.5473086   0.31416467  0.28072387\n",
            "  -0.3200639   0.13206095]\n",
            " [ 0.44109577 -0.4631872  -0.38398668 -0.51395404  0.5238137   0.33407766\n",
            "  -0.40788507 -0.49592605]\n",
            " [ 0.48242337 -0.10961003  0.5510359  -0.1023441  -0.06125005  0.28286958\n",
            "  -0.08981994  0.3645143 ]\n",
            " [ 0.35984546  0.0536099   0.3648138  -0.18187237 -0.20608963 -0.5304044\n",
            "  -0.27740085  0.10848951]\n",
            " [ 0.10698138 -0.24372804  0.05547039 -0.50939536  0.43651766  0.49109\n",
            "  -0.54233885  0.2107395 ]\n",
            " [ 0.25213757  0.3796877   0.5187588  -0.20871824 -0.21454385 -0.39539483\n",
            "   0.5064036   0.03690773]\n",
            " [-0.46060893  0.45331356 -0.5990875  -0.13688365  0.49010918 -0.5819493\n",
            "  -0.09860107 -0.24267262]\n",
            " [ 0.03020731 -0.03157001 -0.3365099  -0.27221328 -0.29117015 -0.5330203\n",
            "  -0.07007976 -0.19783705]\n",
            " [ 0.1227222   0.33144626  0.60911685 -0.35662788 -0.4887145  -0.00934149\n",
            "   0.4311821   0.38094962]\n",
            " [ 0.14207114  0.37753263  0.40717074 -0.53375876  0.19030957  0.46077514\n",
            "   0.06548394 -0.3473546 ]\n",
            " [ 0.06957401  0.15467829  0.42269188 -0.3236341  -0.25600898 -0.13686718\n",
            "  -0.17677404  0.09716266]\n",
            " [-0.49567488 -0.11625047 -0.42329988  0.2229563   0.31679407  0.29877675\n",
            "  -0.00461865 -0.3690283 ]]\n",
            "  Biases shape: (8,)\n",
            "  Biases: \n",
            "[ 0.07339764 -0.84242725  0.8179051   0.         -1.4457246   1.4413279\n",
            " -0.03598021  0.        ]\n",
            "Layer: dense_5\n",
            "  Weights shape: (8, 1)\n",
            "  Weights: \n",
            "[[-0.3821636 ]\n",
            " [ 0.58315736]\n",
            " [-0.29916424]\n",
            " [-0.37197077]\n",
            " [ 0.27859548]\n",
            " [-0.24139792]\n",
            " [ 0.66394204]\n",
            " [ 0.18182302]]\n",
            "  Biases shape: (1,)\n",
            "  Biases: \n",
            "[-1.4167082]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights = model.get_weights()\n",
        "for i, param in enumerate(all_weights):\n",
        "    print(f\"Param {i} shape: {param.shape}\\n{param}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0-uX4K33htm",
        "outputId": "94581b3d-2c62-4d26-ce1f-4d565940b8ed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Param 0 shape: (8, 12)\n",
            "[[ 0.8498324   0.21545744 -0.33652428  0.20295735 -0.03541667  0.24006018\n",
            "   0.3135134   0.24748485  0.18799654 -0.6018367  -0.4972695   0.3225189 ]\n",
            " [-0.11944436 -0.41245276  0.03898498  0.02013337  0.15093817  0.23962247\n",
            "  -0.40880162  0.35415632  0.11143947  0.09002046  0.35852882  0.53698605]\n",
            " [ 0.02552887 -0.23905417  0.34439996  0.36710986  0.06954916 -0.29904783\n",
            "  -0.4717286   0.45152634 -0.46716028  0.22340804  0.41423374  0.3138487 ]\n",
            " [-0.14595951 -0.07469225 -0.01121213  0.03224242 -0.05086758  0.20920625\n",
            "   0.2138151   0.04382552 -0.39622688 -0.3006366  -0.03306048 -0.22746612]\n",
            " [ 0.10700907 -0.37188035  0.31023392 -0.43448615 -0.05638752  0.04078705\n",
            "   0.09040141  0.26195753 -0.14873913 -0.07560864 -0.5981307   0.2791953 ]\n",
            " [-0.25962704  0.08808017 -0.24339545  0.05877262 -0.04299081 -0.06058691\n",
            "   0.5129875  -0.17184612 -0.46844253  0.28884843  0.35076797  0.25309575]\n",
            " [-0.2102152  -0.20375997 -0.39352113  0.01424075 -1.2200372   0.78074396\n",
            "   0.12302073  0.53705597 -0.5732979  -0.31021303 -1.0559897   0.33733156]\n",
            " [ 0.3752883  -0.18541297 -0.4136707  -0.42403415  0.3914155  -0.31846246\n",
            "   0.47788453 -0.28249902  0.17774698  0.23031443 -0.17035532 -0.08985741]]\n",
            "\n",
            "Param 1 shape: (12,)\n",
            "[ 0.07505354  0.          1.249865    0.2867777   0.7731648  -1.0536906\n",
            " -0.25280234 -1.1519884   0.46033248  0.20106636  0.87969685 -0.91006374]\n",
            "\n",
            "Param 2 shape: (12, 8)\n",
            "[[-0.0385626  -0.46050417 -0.24844995 -0.5473086   0.31416467  0.28072387\n",
            "  -0.3200639   0.13206095]\n",
            " [ 0.44109577 -0.4631872  -0.38398668 -0.51395404  0.5238137   0.33407766\n",
            "  -0.40788507 -0.49592605]\n",
            " [ 0.48242337 -0.10961003  0.5510359  -0.1023441  -0.06125005  0.28286958\n",
            "  -0.08981994  0.3645143 ]\n",
            " [ 0.35984546  0.0536099   0.3648138  -0.18187237 -0.20608963 -0.5304044\n",
            "  -0.27740085  0.10848951]\n",
            " [ 0.10698138 -0.24372804  0.05547039 -0.50939536  0.43651766  0.49109\n",
            "  -0.54233885  0.2107395 ]\n",
            " [ 0.25213757  0.3796877   0.5187588  -0.20871824 -0.21454385 -0.39539483\n",
            "   0.5064036   0.03690773]\n",
            " [-0.46060893  0.45331356 -0.5990875  -0.13688365  0.49010918 -0.5819493\n",
            "  -0.09860107 -0.24267262]\n",
            " [ 0.03020731 -0.03157001 -0.3365099  -0.27221328 -0.29117015 -0.5330203\n",
            "  -0.07007976 -0.19783705]\n",
            " [ 0.1227222   0.33144626  0.60911685 -0.35662788 -0.4887145  -0.00934149\n",
            "   0.4311821   0.38094962]\n",
            " [ 0.14207114  0.37753263  0.40717074 -0.53375876  0.19030957  0.46077514\n",
            "   0.06548394 -0.3473546 ]\n",
            " [ 0.06957401  0.15467829  0.42269188 -0.3236341  -0.25600898 -0.13686718\n",
            "  -0.17677404  0.09716266]\n",
            " [-0.49567488 -0.11625047 -0.42329988  0.2229563   0.31679407  0.29877675\n",
            "  -0.00461865 -0.3690283 ]]\n",
            "\n",
            "Param 3 shape: (8,)\n",
            "[ 0.07339764 -0.84242725  0.8179051   0.         -1.4457246   1.4413279\n",
            " -0.03598021  0.        ]\n",
            "\n",
            "Param 4 shape: (8, 1)\n",
            "[[-0.3821636 ]\n",
            " [ 0.58315736]\n",
            " [-0.29916424]\n",
            " [-0.37197077]\n",
            " [ 0.27859548]\n",
            " [-0.24139792]\n",
            " [ 0.66394204]\n",
            " [ 0.18182302]]\n",
            "\n",
            "Param 5 shape: (1,)\n",
            "[-1.4167082]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Predict diabetes for new samples (3 new patients)\n",
        "samples = np.array([[6, 148, 72, 35, 0, 33.6, 0.627, 50],   # Sample 1\n",
        "                    [1, 85, 66, 29, 0, 26.6, 0.351, 31],    # Sample 2\n",
        "                    [8, 183, 64, 0, 0, 23.3, 0.672, 32]])   # Sample 3\n",
        "\n",
        "# Standardize the new data using the same scaler\n",
        "#samples_scaled = scaler.transform(samples)"
      ],
      "metadata": {
        "id": "ne94Z7xi0heX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict diabetes (returns probabilities)\n",
        "predictions = model.predict(samples)\n",
        "\n",
        "# Convert probabilities to class labels (0 or 1)\n",
        "predicted_classes = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Output predictions\n",
        "print(\"Predictions for the samples (0 = No Diabetes, 1 = Diabetes):\")\n",
        "print(predicted_classes.flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKzIpAs1042W",
        "outputId": "a7e9c121-731b-4b8e-a32e-d99567462018"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "Predictions for the samples (0 = No Diabetes, 1 = Diabetes):\n",
            "[1 0 1]\n"
          ]
        }
      ]
    }
  ]
}